<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet" href="http://skiadas.github.io/css/course.css" type="text/css" />
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body>
<h1 id="general-theory-on-modeling-and-data-fitting">General Theory on Modeling and Data Fitting</h1>
<h2 id="notes">Notes</h2>
<p>In modeling our goal is typically to explain and/or predict the values of a target variable, given values of other variables and some modeling assumptions.</p>
<h3 id="terminology-and-general-methodology">Terminology and General Methodology</h3>
<p>Here are some key terms:</p>
<dl>
<dt>Target Variable</dt>
<dd>One variable is the target of our modeling process. Our ultimate goal is to understand that variable in terms of others.
</dd>
<dt>Predictor Variables</dt>
<dd>Zero or more variables, which we expect to be related to the target variable. We want to be able to say something about the target variable <em>given</em> values for the predictor variables
</dd>
<dt>Model Formula</dt>
<dd><p>A specific formula / function of the predictor variables and some parameters, whose output is meant to model the target variable. We would write this in general form as:</p>
<p><span class="math">\[Y \sim f(X_1, X_2, ...; \beta_1,\beta_2, ...)\]</span></p>
<p>where <span class="math">\(Y\)</span> is the target variable, <span class="math">\(X_1\)</span>, <span class="math">\(X_2\)</span>, … are the predictor variables, and <span class="math">\(\beta_1\)</span>, <span class="math">\(\beta_2\)</span>, … are parameters, values to be determined.</p>
</dd>
<dt>Model Fit</dt>
<dd>We say that we <em>fit</em> the model to the data, if using the data we determine values for the parameters <span class="math">\(\beta_1\)</span>, … that give in some sense the “optimal” fit. This results in a <strong>specific model</strong>, rather than the <strong>general model</strong> of the previous point.
</dd>
<dt>Predicted Values</dt>
<dd>Given a specific model, for any set of values for <span class="math">\(X_1\)</span>, <span class="math">\(X_2\)</span>, …, we can use the formula to compute a specific value for <span class="math">\(Y\)</span>. This is called the <em>predicted value</em>. These values are usually denoted by <span class="math">\(\hat y\)</span>.
</dd>
<dt>Actual Values</dt>
<dd>These are the value that <span class="math">\(Y\)</span> has in the actual data. More often denoted as <span class="math">\(y\)</span>.
</dd>
<dt>Residuals</dt>
<dd>The differences between the Actual Values and the Predicted Values, <span class="math">\(y - \hat y\)</span>. You can think of the residuals as telling you how far your specific model is from accurately predicting your actual values. In other words, they measure how much of an error you are making when predicting.
</dd>
<dt>SSR/RSS</dt>
<dd><p>The “Sum of Squared Residuals”, sometimes called “Residual Sum of Squares”. This is a measure of the overall error you are making at all your data points together.</p>
<p>Some times we adjust this by dividing by <span class="math">\(n-1\)</span> or something similar.</p>
<p>Normal modeling techniques try to choose the parameters so as to minimize this sum.</p>
</dd>
</dl>
<p>It is important to identify some key steps in the process:</p>
<ol style="list-style-type: decimal">
<li>You have to decide what variables <span class="math">\(X_1\)</span>, <span class="math">\(X_2\)</span>, … to include. We will largely dodge this question.</li>
<li>You have to decide how to combine them, i.e. what form the function <span class="math">\(f\)</span> will take. We will restrict ourselves to linear functions, but there are other options out there.</li>
<li>You have to decide how to assess how good a fit you have. We will use SSR for this, but there are other options out there.</li>
<li>You have to find the parameter values that for your given choice of form for the function <span class="math">\(f\)</span> achieve the best fit, in whatever way you have defined it.</li>
<li>You have to assess if that is a good fit, or whether you should look for other function forms <span class="math">\(f\)</span>.</li>
</ol>
<p>We will focus exclusively on linear functions of one predictor variable, so we will not be able to do many of these. But in this introduction I will talk about some of these concepts in more general terms.</p>
<h3 id="model-examples">Model Examples</h3>
<p>Here are some basic examples of the above ideas. Our target variable is student GPA, we want to try to find a way to predict it.</p>
<h4 id="constant">Constant</h4>
<p>This is the simplest model we can try to fit. We have no predictor variables, so all we can do is predict a single number.</p>
<p>In terms of equations it might look like <span class="math">\(Y \sim \beta\)</span> where <span class="math">\(\beta\)</span> is the parameter. All we have to do to “fit” the model is to provide a constant value for the parameter. So we could for instance say <span class="math">\(Y \sim 2.93\)</span>, meaning that we predict that the student’s GPA is equal to <span class="math">\(2.93\)</span>.</p>
<p>The predicted values in this case are always equal to this constant value. The residuals are the differences <span class="math">\(y - \beta\)</span>.</p>
<p>It turns out, that if we want to choose a value for <span class="math">\(\beta\)</span> that makes the SSR as small as possible, then we must choose <span class="math">\(\beta = \bar y\)</span>, the mean of the <span class="math">\(y\)</span> values.</p>
<blockquote>
<p>The best constant model fit is when that constant is equal to the mean of the <span class="math">\(y\)</span> values, <span class="math">\(\bar y\)</span>. The Adjusted SSR measure in this case equals the <em>variance</em> of <span class="math">\(y\)</span>.</p>
</blockquote>
<h4 id="factors">Factors</h4>
<p>Another common case is when we try to have a predictor variable that is categorical. These are often called “factors”. For instance we could say that we will try to predict the student’s GPA based on their gender.</p>
<p>In this case we would basically need to provide two parameter values: One parameter for our guess for the GPA if the student is male, and another for the GPA if the student is female.</p>
<p>It turns out that the best guesses in this case are again the means of the male and female students respectively.</p>
<h4 id="linear-equation">Linear Equation</h4>
<p>The most common model, and one we will spend more time with next week, is that of a linear equation. For example, perhaps we think that a student’s high-school gpa should be a good predictor of their college gpa. In that case, if we denote a student’s high-school GPA with <span class="math">\(x\)</span> and their college gpa with <span class="math">\(y\)</span>, we would be looking for an equation of the form:</p>
<p><span class="math">\[y = a + b x\]</span></p>
<p>Where <span class="math">\(a,b\)</span> are the parameters, and we would like to choose their “best values” to fit the data in any given scenario. We will explore this more in the next section.</p>
</body>
</html>
